# Bounding Box Data Flow - Visual Walkthrough

This document traces exactly how a detected object gets drawn on screen.

## Complete Flow Example

**Scenario:** Person detected at (200, 150) to (300, 250) in camera frame

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAMERA STREAM (192.168.1.107:554/stream1)                 â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ Resolution: 800Ã—600                                        â”‚
â”‚ Frame Rate: 15 FPS                                         â”‚
â”‚ Format: H.264 RTSP                                         â”‚
â”‚ Pixel Space: X=[0, 800), Y=[0, 600)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DESKTOP APP: StreamWorker Thread                           â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ File: desktop_app/main.py, lines 23-72                    â”‚
â”‚ Task: Continuously read frames from RTSP stream            â”‚
â”‚                                                            â”‚
â”‚ Code:                                                      â”‚
â”‚   cap = cv2.VideoCapture(rtsp_url)  # 800Ã—600 stream      â”‚
â”‚   while True:                                              â”‚
â”‚       ret, frame = cap.read()  # Frame shape: (600,800,3) â”‚
â”‚       self.frame_ready.emit(frame)  # Signal to GUI       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                Frame: 800Ã—600 BGR numpy array
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DESKTOP APP: update_frame() Slot                           â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ File: desktop_app/main.py, lines 655-690                  â”‚
â”‚ Task: Process frame and display                            â”‚
â”‚                                                            â”‚
â”‚ Code:                                                      â”‚
â”‚   def on_frame_ready(self, frame):                         â”‚
â”‚       # Apply frame skipping (every 3rd frame)            â”‚
â”‚       if self.frame_skip_counter % 3 == 0:               â”‚
â”‚           display_frame = self.draw_detections(frame)    â”‚
â”‚       self.display_frame_as_pixmap(display_frame)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DESKTOP APP: draw_detections_overlay()                     â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ File: desktop_app/main.py, lines 742-870                  â”‚
â”‚ Task: Fetch detections from backend and draw on frame      â”‚
â”‚                                                            â”‚
â”‚ Step 1: Fetch Detections                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚   if time_since_last_fetch >= 0.2s:  # Throttle to 5 FPS  â”‚
â”‚       response = requests.get(                             â”‚
â”‚           'http://localhost:8000/api/detections/current'  â”‚
â”‚       )                                                    â”‚
â”‚       detections = response.json()                         â”‚
â”‚   # Returns: [                                             â”‚
â”‚   #   {                                                    â”‚
â”‚   #     'class': 'person',                                 â”‚
â”‚   #     'confidence': 0.92,                                â”‚
â”‚   #     'bbox': [200, 150, 300, 250]  â† IN BACKEND SPACE  â”‚
â”‚   #   }                                                    â”‚
â”‚   # ]                                                      â”‚
â”‚                                                            â”‚
â”‚ Step 2: Get Frame Dimensions                              â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚   frame_height, frame_width = frame.shape[:2]             â”‚
â”‚   # Result: frame_width=800, frame_height=600             â”‚
â”‚                                                            â”‚
â”‚ Step 3: Calculate Scale Factors                           â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚   BACKEND_WIDTH, BACKEND_HEIGHT = 800, 600                â”‚
â”‚   scale_x = frame_width / BACKEND_WIDTH = 800/800 = 1.0   â”‚
â”‚   scale_y = frame_height / BACKEND_HEIGHT = 600/600 = 1.0 â”‚
â”‚   max_valid_x = frame_width = 800                         â”‚
â”‚   max_valid_y = frame_height = 600                        â”‚
â”‚                                                            â”‚
â”‚ Step 4: Transform Detection Coordinates                   â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚   Original bbox (backend space):                          â”‚
â”‚     x1, y1, x2, y2 = 200, 150, 300, 250                   â”‚
â”‚                                                            â”‚
â”‚   Scale to frame space:                                   â”‚
â”‚     x1 = int(200 * 1.0) = 200                             â”‚
â”‚     y1 = int(150 * 1.0) = 150                             â”‚
â”‚     x2 = int(300 * 1.0) = 300                             â”‚
â”‚     y2 = int(250 * 1.0) = 250                             â”‚
â”‚   (Result: no change since scale is 1.0)                  â”‚
â”‚                                                            â”‚
â”‚ Step 5: Clamp to Frame Boundaries                         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚   x1 = max(0, min(200, 799)) = 200  âœ“ within [0, 800)   â”‚
â”‚   x2 = max(201, min(300, 800)) = 300 âœ“ within [0, 800)   â”‚
â”‚   y1 = max(0, min(150, 599)) = 150  âœ“ within [0, 600)   â”‚
â”‚   y2 = max(151, min(250, 600)) = 250 âœ“ within [0, 600)   â”‚
â”‚                                                            â”‚
â”‚   CRITICAL: This prevents boxes from appearing in         â”‚
â”‚   black bars if the display scales the frame              â”‚
â”‚                                                            â”‚
â”‚ Step 6: Validate Box Dimensions                           â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚   if x2 <= x1 or y2 <= y1:                                â”‚
â”‚       continue  # Skip invalid boxes                      â”‚
â”‚   # Check: 300 > 200? Yes âœ“  250 > 150? Yes âœ“            â”‚
â”‚   # Box is valid, proceed to draw                         â”‚
â”‚                                                            â”‚
â”‚ Step 7: Draw Box on Frame                                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚   color = (0, 255, 0)  # Green for 'person'               â”‚
â”‚   cv2.rectangle(frame, (200, 150), (300, 250),            â”‚
â”‚                 color=(0,255,0), thickness=2)             â”‚
â”‚   # Modifies frame in-place: pixels drawn at coordinates  â”‚
â”‚                                                            â”‚
â”‚ Step 8: Draw Label Text                                   â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚   text = "person 0.92"                                    â”‚
â”‚   label_y = max(25, 150-5) = 145                          â”‚
â”‚   cv2.putText(frame, text, (200, 145), ...)               â”‚
â”‚                                                            â”‚
â”‚ Step 9: Return Annotated Frame                            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚   return frame  # 800Ã—600 BGR with box drawn              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
            Frame with box: 800Ã—600 with green rectangle
            at coordinates (200, 150) to (300, 250)
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DESKTOP APP: Display Frame as QPixmap                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ File: desktop_app/main.py, lines 690-740                  â”‚
â”‚ Task: Convert frame to image and display in label          â”‚
â”‚                                                            â”‚
â”‚ Step 1: Convert Frame to RGB (if overlay enabled)         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚   if self.overlay_enabled:                                â”‚
â”‚       display_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)â”‚
â”‚   # Result: RGB array, still 800Ã—600 with green box       â”‚
â”‚                                                            â”‚
â”‚ Step 2: Create QImage from Frame Data                     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚   bytes_per_line = 800 * 3  # 3 bytes per pixel RGB      â”‚
â”‚   qt_image = QImage(display_frame.data, 800, 600,         â”‚
â”‚                     bytes_per_line,                       â”‚
â”‚                     QImage.Format_RGB888)                 â”‚
â”‚   # Result: QImage object, 800Ã—600                        â”‚
â”‚                                                            â”‚
â”‚ Step 3: Create QPixmap from QImage                        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚   pixmap = QPixmap.fromImage(qt_image)                    â”‚
â”‚   # Result: QPixmap, 800Ã—600 with green box               â”‚
â”‚                                                            â”‚
â”‚ Step 4: Scale Pixmap to Fit Label with Aspect Ratio      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚   label_width = self.video_label.width()   # e.g., 1200   â”‚
â”‚   label_height = self.video_label.height() # e.g., 900    â”‚
â”‚                                                            â”‚
â”‚   scaled_pixmap = pixmap.scaledToWidth(1200,              â”‚
â”‚                                       Qt.SmoothTransformation)â”‚
â”‚   # Result: 1200Ã—900 (scaled 1.5x, maintains 4:3 ratio)   â”‚
â”‚   # Box scaled: (300, 225) to (450, 375)  [1.5x]          â”‚
â”‚                                                            â”‚
â”‚   if scaled_pixmap.height() > label_height:               â”‚
â”‚       scaled_pixmap = pixmap.scaledToHeight(900, ...)     â”‚
â”‚   # Check: 900 > 900? No, skip this step                 â”‚
â”‚                                                            â”‚
â”‚ Step 5: Set Pixmap in Label                               â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚   self.video_label.setPixmap(scaled_pixmap)               â”‚
â”‚   # Label displays 1200Ã—900 pixmap inside 1200Ã—900 label  â”‚
â”‚   # No black bars (label and pixmap match size)           â”‚
â”‚   # GREEN BOX visible at scaled coordinates               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                âœ… Green bounding box appears on screen!
                   at position (300, 225) to (450, 375)
                   relative to label display area
```

## Coordinate Transformation Summary

```
Backend Detection Space        Frame Processing Space      Display Space
      (800Ã—600)                    (800Ã—600)               (varies)
      
   Bbox in:                    Bbox in:                  Bbox in:
[200, 150, 300, 250]    â†’    [200, 150, 300, 250]   â†’  [300, 225, 450, 375]
                              (scale=1.0)                (scaled 1.5x)
                              (clamped)                  (via PyQt)
                              (validated)
```

## Key Points

### âœ… What Goes Right
1. Frame stays 800Ã—600 throughout processing
2. Detections fetched in backend space (800Ã—600)
3. Coordinates scaled correctly (1.0x in this case)
4. Coordinates clamped to valid range
5. PyQt automatically handles display scaling and black bars
6. Bounding box position preserved relative to frame content

### âš ï¸ What Could Go Wrong
1. **Scale factor wrong:** If frame != 800Ã—600, scaling would be off
2. **Coordinates out of bounds:** If bbox > [800, 600], clamping catches it
3. **Double scaling:** If coordinates scaled twice, boxes would jump
4. **Frame resized before overlay:** Would throw off coordinates
5. **Mixed coordinate spaces:** Using display coords on frame pixels

### ğŸ” Debugging Tips
```python
# At start of draw_detections_overlay():
frame_height, frame_width = frame.shape[:2]
print(f"Frame dimensions: {frame_width}Ã—{frame_height}")
print(f"Scale factors: x={scale_x}, y={scale_y}")

# Before drawing each box:
print(f"Bbox before transform: {[x1, y1, x2, y2]}")
print(f"Bbox after clamp: {[x1, y1, x2, y2]}")

# After drawing:
if detections_drawn > 0:
    print(f"Drew {detections_drawn} boxes")
```

## Real-World Scenarios

### Scenario A: Subject at Top Edge
```
Detection returns: bbox=[300, 10, 350, 100]
After clamp: (300,10) to (350,100)  âœ“ Valid, within frame
Draw result: Box visible at top of frame
```

### Scenario B: Subject at Right Edge
```
Detection returns: bbox=[750, 250, 810, 350]  â† X exceeds 800
After clamp: (750,250) to (800,350)  â† X2 clamped to 800
Draw result: Partially visible box at right edge
```

### Scenario C: Partially Outside Frame
```
Detection returns: bbox=[700, 550, 900, 700]  â† Outside
After clamp: (700,550) to (800,600)  â† Both axes clamped
Draw result: Small box visible in corner
```

### Scenario D: Completely Outside Frame
```
Detection returns: bbox=[850, 650, 950, 750]  â† Completely outside
After clamp: x2 < x1 or y2 < y1  â† Invalid
Draw result: Box skipped, not drawn
```

## Performance Impact

### Frame Processing
- Detection inference: 100-150ms (async, every 3rd frame)
- Coordinate transform: <1ms (simple math)
- Clamping: <1ms (min/max operations)
- Drawing: 2-5ms (cv2.rectangle, cv2.putText)
- **Total per frame:** ~200ms (only every 3rd frame drawn)

### Memory
- Frame buffer: 1.4 MB (800Ã—600 BGR)
- Detection data: <10 KB (1-5 boxes)
- Cached detections: ~5 KB
- **Total:** ~1.5 MB active, minimal overhead

### CPU
- YOLO inference: Largest consumer (30-50% alone)
- Frame conversion: ~5-10%
- Drawing operations: ~5-10%
- PyQt rendering: ~10-20%
- **Total before optimization:** 60-70%
- **Total after optimization:** Expected 20-30%

---

**Key Takeaway:** The bounding box coordinate system is working correctly. PyQt handles display scaling and black bars automatically. Boxes are drawn in frame space (800Ã—600) and clamped to valid boundaries.
